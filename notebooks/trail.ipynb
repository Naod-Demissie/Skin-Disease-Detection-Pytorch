{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from enum import Enum\n",
    "from typing import Optional, Tuple, List\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "ROOT_DIR = 'D:/Projects/Skin-Disease-Detection-Pytorch'\n",
    "sys.path.append(ROOT_DIR)\n",
    "from src.utils.config import *\n",
    "from src.utils.dataloader import *\n",
    "from src.utils.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DermnetDataset(Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            data: Tuple[str, int], \n",
    "            transform: Optional[transforms.Compose] = None\n",
    "    ) -> None:\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        image_path, label = self.data[index]\n",
    "        image = Image.open(image_path)\n",
    "        label = torch.tensor(label)\n",
    "        label = F.one_hot(label, num_classes=len(DERMNET_LABEL_NAME)).float()\n",
    "        \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label, image_path\n",
    "\n",
    "\n",
    "\n",
    "def _transforms(resize_size, crop_size):\n",
    "    train_transform = transforms.Compose(\n",
    "            [\n",
    "                # transforms.ToPILImage(),\n",
    "                transforms.Resize(resize_size[:-1]),\n",
    "                transforms.CenterCrop(crop_size[:-1]),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        )\n",
    "    val_transform = transforms.Compose(\n",
    "            [\n",
    "                # transforms.ToPILImage(),\n",
    "                transforms.Resize(resize_size[:-1]),\n",
    "                transforms.CenterCrop(crop_size[:-1]),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    test_transform= transforms.Compose(\n",
    "            [\n",
    "                # transforms.ToPILImage(),\n",
    "                transforms.Resize(resize_size[:-1]),\n",
    "                transforms.CenterCrop(crop_size[:-1]),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    return train_transform, val_transform, test_transform\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def prepare_dermnet_data(\n",
    "        resize_size: Tuple[int, int, int], \n",
    "        crop_size: Tuple[int, int, int], \n",
    "        batch_size: int, \n",
    "        num_workers: int\n",
    ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    \n",
    "    DERMNET_DATA_DIR = 'D:/Datasets/Skin-Disease-Detection/dataset/Dermnet'\n",
    "    label_names = os.listdir(f'{DERMNET_DATA_DIR}/train')\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    for label in label_names:\n",
    "        file_paths = glob(f'{DERMNET_DATA_DIR}/train/{label}/*')\n",
    "        train_paths, val_paths = train_test_split(file_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "        sparse_label = label_names.index(label)\n",
    "        train_data += [(path, sparse_label) for path in train_paths]\n",
    "        val_data += [(path, sparse_label) for path in val_paths]\n",
    "\n",
    "    test_data = []\n",
    "    for label in label_names:\n",
    "        file_paths = glob(f'{DERMNET_DATA_DIR}/test/{label}/*')\n",
    "        sparse_label = label_names.index(label)\n",
    "        test_data += [(path, sparse_label) for path in file_paths]\n",
    "\n",
    "\n",
    "    train_transform, val_transform, test_transform = _transforms(resize_size[:-1], crop_size[:-1])\n",
    "\n",
    "    train_ds = DermnetDataset(data=train_data, transform=train_transform)\n",
    "    val_ds = DermnetDataset(data=val_data, transform=val_transform)\n",
    "    test_ds = DermnetDataset(data=test_data, transform=test_transform)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=True,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=True,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=True,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "torch.Size([3, 224, 224]) tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0.]) D:/Datasets/Skin-Disease-Detection/dataset/Dermnet/train/Eczema Photos\\lichen-simplex-chronicus-114.jpg\n"
     ]
    }
   ],
   "source": [
    "DERMNET_DATA_DIR = 'D:/Datasets/Skin-Disease-Detection/dataset/Dermnet'\n",
    "label_names = os.listdir(f'{DERMNET_DATA_DIR}/train')\n",
    "train_data = []\n",
    "val_data = []\n",
    "for label in label_names:\n",
    "    file_paths = glob(f'{DERMNET_DATA_DIR}/train/{label}/*')\n",
    "    train_paths, val_paths = train_test_split(file_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "    sparse_label = label_names.index(label)\n",
    "    train_data += [(path, sparse_label) for path in train_paths]\n",
    "    val_data += [(path, sparse_label) for path in val_paths]\n",
    "\n",
    "# test_data = []\n",
    "# for label in label_names:\n",
    "#     file_paths = glob(f'{DERMNET_DATA_DIR}/test/{label}/*')\n",
    "#     sparse_label = label_names.index(label)\n",
    "#     test_data += [(path, sparse_label) for path in file_paths]\n",
    "\n",
    "\n",
    "train_transform, val_transform, test_transform = _transforms((256, 256), (224, 224))\n",
    "\n",
    "train_ds = DermnetDataset(data=train_data, transform=train_transform)\n",
    "# val_ds = DermnetDataset(data=val_data, transform=val_transform)\n",
    "# test_ds = DermnetDataset(data=test_data, transform=test_transform)\n",
    "\n",
    "img, label, image_path = train_ds.__getitem__(3200)\n",
    "print(img.shape, label, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Your continuous label tensor\n",
    "label = torch.from_numpy(np.arange(5, 10))\n",
    "\n",
    "# Convert to integer indices\n",
    "label_indices = (label.float() - label.min().float()).long()\n",
    "label_indices\n",
    "# Apply F.one_hot\n",
    "# one_hot_label = F.one_hot(label_indices, num_classes=7)\n",
    "\n",
    "# print(one_hot_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(base_model_name):\n",
    "    assert base_model_name in [\n",
    "        'resnet18',\n",
    "        'resnet50',\n",
    "        'efficientnet_b0', \n",
    "        'efficientnet_b1', \n",
    "        'efficientnet_b2', \n",
    "        'efficientnet_b3', \n",
    "        'efficientnet_b4', \n",
    "        'efficientnet_v2_s', \n",
    "        'efficientnet_v2_m'\n",
    "    ], f'Invalid base model name: {base_model_name}'\n",
    "\n",
    "    return (\n",
    "        resnet18(weights=None) if base_model_name == 'resnet18' else\n",
    "        resnet50(weights=None) if base_model_name == 'resnet50' else\n",
    "        efficientnet_b0(weights=None) if base_model_name == 'efficientnet_b0' else\n",
    "        efficientnet_b1(weights=None) if base_model_name == 'efficientnet_b1' else\n",
    "        efficientnet_b2(weights=None) if base_model_name == 'efficientnet_b2' else\n",
    "        efficientnet_b3(weights=None) if base_model_name == 'efficientnet_b3' else\n",
    "        efficientnet_b4(weights=None) if base_model_name == 'efficientnet_b4' else\n",
    "        efficientnet_v2_s(weights=None) if base_model_name == 'efficientnet_v2_s' else\n",
    "        efficientnet_v2_m(weights=None)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Network(nn.Module):\n",
    "#     def __init__(\n",
    "#             self, \n",
    "#             base_model, \n",
    "#             dropout: float, \n",
    "#             output_dims: List[int],\n",
    "#             num_classes: int\n",
    "#     ) -> None:\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.base_model = base_model\n",
    "#         input_dim: int = base_model.classifier[1].in_features\n",
    "\n",
    "#         layers: List[nn.Module] = []\n",
    "#         for output_dim in output_dims:\n",
    "#             layers.append(nn.Linear(input_dim, output_dim))\n",
    "#             layers.append(nn.ReLU())\n",
    "#             layers.append(nn.Dropout(dropout))\n",
    "#             input_dim = output_dim\n",
    "#         layers.append(nn.Linear(input_dim, num_classes))\n",
    "#         layers.append(nn.Softmax(dim=-1))\n",
    "\n",
    "#         self.base_model.classifier = nn.Sequential(*layers)\n",
    "    \n",
    "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         return self.base_model(x)\n",
    "    \n",
    "\n",
    "# class ResNetwork(nn.Module):\n",
    "#     def __init__(\n",
    "#             self, \n",
    "#             base_model, \n",
    "#             dropout: float, \n",
    "#             output_dims: List[int],\n",
    "#             num_classes: int\n",
    "#     ) -> None:\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.base_model = base_model\n",
    "#         input_dim: int = base_model.fc.in_features\n",
    "\n",
    "#         layers: List[nn.Module] = []\n",
    "#         for output_dim in output_dims:\n",
    "#             layers.append(nn.Linear(input_dim, output_dim))\n",
    "#             layers.append(nn.ReLU())\n",
    "#             layers.append(nn.Dropout(dropout))\n",
    "#             input_dim = output_dim\n",
    "#         layers.append(nn.Linear(input_dim, num_classes))\n",
    "#         layers.append(nn.Softmax(dim=-1))\n",
    "\n",
    "#         self.base_model.fc = nn.Sequential(*layers)\n",
    "    \n",
    "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "#         return self.base_model(x)\n",
    "    \n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            base_model, \n",
    "            dropout: float, \n",
    "            output_dims: List[int],\n",
    "            num_classes: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.base_model = base_model\n",
    "        if base_model.__class__.__name__ == 'ResNet':\n",
    "            input_dim: int = base_model.fc.in_features \n",
    "        elif base_model.__class__.__name__ == 'EfficientNet':\n",
    "            input_dim: int = base_model.classifier[1].in_features\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        for output_dim in output_dims:\n",
    "            layers.append(nn.Linear(input_dim, output_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            input_dim = output_dim\n",
    "        layers.append(nn.Linear(input_dim, num_classes))\n",
    "        layers.append(nn.Softmax(dim=-1))\n",
    "\n",
    "\n",
    "        if base_model.__class__.__name__ == 'ResNet':\n",
    "            self.base_model.fc = nn.Sequential(*layers) \n",
    "        elif base_model.__class__.__name__ == 'EfficientNet':\n",
    "            self.base_model.classifier = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = 'resnet50'\n",
    "base_model_name = 'efficientnet_b0'\n",
    "\n",
    "\n",
    "model = get_base_model(base_model_name)\n",
    "\n",
    "MODEL = Network(\n",
    "    base_model=get_base_model(base_model_name),\n",
    "    dropout=None,\n",
    "    output_dims=[],\n",
    "    num_classes=len(DERMNET_LABEL_NAME)\n",
    ") \n",
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12438, 3119, 4002)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data, test_data = prepare_dermnet_data()\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 224, 224]) torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, _, _ = local_dataloader(\n",
    "    resize_size=(256, 256, 3),\n",
    "    crop_size=(224, 224, 3),\n",
    "    batch_size=10,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "for image, label in train_dataloader:\n",
    "    print(image.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
